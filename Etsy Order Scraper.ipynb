{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244def6c",
   "metadata": {},
   "source": [
    "#### This is my Etsy Program that scrapes an Etsy CSV and cleans the data for easy analysis\n",
    "\n",
    "###### Essentially, the CSV files provided by Etsy are messy and unusable without ample cleaning. \n",
    "\n",
    "###### This program automates that process by creating a list of the months orders and any revenues/costs associated with each.\n",
    "\n",
    "###### This code does the following:\n",
    "\n",
    "- Loads any csv files in the specified path.\n",
    "- Cleans the data for analysis.\n",
    "- Collects any costs/revenue associated with an order.\n",
    "- Totals the costs and revenue and outputs a new CSV file with each order and the associated net revenue/cost.\n",
    "\n",
    "###### An example of what this codes achieves:\n",
    "\n",
    "###### Before (Total of 416 rows): https://imgur.com/a/KBgMOlr\n",
    "\n",
    "###### After: https://imgur.com/a/f5nAvA0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bd477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36dd9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if \"Order\" is present in a DataFrame row\n",
    "def contains_order(row):\n",
    "    return any(\"Order\" in str(x) for x in row)\n",
    "\n",
    "# Etsy_Scraper function to scrape data from CSV files and extract necessary details\n",
    "def Etsy_Scraper():\n",
    "    \n",
    "    # Define the path to the directory where CSV files are located\n",
    "    path = 'C:\\\\Users\\\\User\\\\Python\\\\Projects\\\\Etsy Scraper\\\\Etsy Data'\n",
    "    output_path = 'C:\\\\Users\\\\User\\\\Python\\\\Projects\\\\Etsy Scraper\\\\Scraped Data'\n",
    "    extension = 'csv'\n",
    "    os.chdir(path)\n",
    "    result = glob.glob('*.{}'.format(extension))\n",
    "\n",
    "    # Loop over all CSV files in the directory\n",
    "    for entry in result:\n",
    "        # Only process files that contain 'etsy_statement' in their name\n",
    "        if 'etsy_statement' in entry:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            order_df = pd.read_csv(entry)\n",
    "\n",
    "            # Select necessary columns and process the date\n",
    "            order_df =  order_df[[\"Date\", \"Type\", \"Title\", \"Info\", \"Net\"]]\n",
    "            date = order_df['Date'].iloc[0]\n",
    "            date = date.replace(',','')\n",
    "            date = datetime.strptime(date, '%d %B %Y')\n",
    "            month = date.month\n",
    "            year = date.year\n",
    "\n",
    "            # Create a DataFrame for sales and process it\n",
    "            sale_df = order_df[[\"Date\", \"Type\", \"Title\", \"Net\"]]\n",
    "            sale_df = sale_df[sale_df.apply(contains_order, axis=1)]\n",
    "            sale_df.rename(columns={'Title': 'order #'},inplace=True)\n",
    "            sale_df['order #'] = sale_df['order #'].apply(lambda x: x[x.find('#'):])\n",
    "            sale_df['Net'] = sale_df['Net'].apply(lambda x:x.replace(',',''))\n",
    "            sale_df['Net'] = sale_df['Net'].apply(lambda x:float(x.replace('CA$','')))\n",
    "\n",
    "            # Create a DataFrame for costs and process it\n",
    "            cost_df = order_df[[\"Date\", \"Type\", \"Info\", \"Net\"]]\n",
    "            cost_df = cost_df[cost_df.apply(contains_order, axis=1)]\n",
    "            cost_df.rename(columns={'Info': 'order #'},inplace=True)\n",
    "            cost_df['order #'] = cost_df['order #'].apply(lambda x: x[x.find('#'):])\n",
    "            cost_df['Net'] = cost_df['Net'].apply(lambda x:float(x.replace('CA$','')))\n",
    "\n",
    "            # Merge the sales and costs DataFrames, group by 'order #' and sum 'Net'\n",
    "            merged_df = pd.concat([sale_df, cost_df])\n",
    "            merged_df = merged_df[['order #', 'Type', 'Net', 'Date']]\n",
    "            merged_df = merged_df.groupby('order #').Net.sum().reset_index()\n",
    "\n",
    "            # Save the merged DataFrame to a CSV file\n",
    "            output_file = 'scraped_financials_{}_{}.csv'.format(year, month)\n",
    "            output_file_path = os.path.join(output_path, output_file)\n",
    "            merged_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291691c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine_Data function to combine all scraped CSV files into one\n",
    "def Combine_Data():\n",
    "\n",
    "    path = 'C:\\\\Users\\\\User\\\\Python\\\\Projects\\\\Etsy Scraper\\\\Scraped Data'\n",
    "    output_path = 'C:\\\\Users\\\\User\\\\Python\\\\Projects\\\\Etsy Scraper\\\\Combined Data'\n",
    "    extension = 'csv'\n",
    "    os.chdir(path)\n",
    "    result = glob.glob('*.{}'.format(extension))\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    # Loop over all CSV files in the directory\n",
    "    for entry in result:\n",
    "        # Only process files that contain 'scraped_financials' in their name\n",
    "        if 'scraped_financials' in entry:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            order_df = pd.read_csv(entry)\n",
    "            order_df = order_df[[\"order #\", \"Net\"]]\n",
    "\n",
    "            # Append the DataFrame to the all_data list\n",
    "            all_data.append(order_df)\n",
    "\n",
    "    # Concatenate all DataFrames in the all_data list\n",
    "    all_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Group by 'order #' and sum the 'Net' values\n",
    "    all_data = all_data.groupby('order #', as_index=False).agg({'Net': 'sum'})\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    output_file = 'all_data.csv'\n",
    "    output_file_path = os.path.join(output_path, output_file)\n",
    "    all_data.to_csv(output_file_path, index=False)\n",
    "    all_data.to_csv('concatenated_financials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57845232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Etsy_Scraper and Combine_Data functions\n",
    "Etsy_Scraper()\n",
    "Combine_Data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
